---
title: "Assignment 5: Mixed models"
author: "Marton Kovacs / Zoltan Kekecs"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction

This assignment is related to the previous lab assignment concerning perioperative pain and its psychological and hormonal predictors. Just like previously, you will set up linear model to predict postoperative pain after wisdom tooth surgery, but this time you will have to also take into account the fact that there is clustering in the data. 

Your research paper on the effect of the psychological and hormonal predictors of postoperative pain was so successful, that you managed to secure research funding for a multi-site replication study. Here your collaborators collect data in the same way you did in the original study at 20 different hospital sites. The goal of the study is to increase the generalizability of your findings. You would like to assess the model coefficients and the overall predictive efficiency of the predictors in your model.

As a reminder, here is the protocol for data collection: “You have collected data from adults who were scheduled to undergo surgical extraction of the third mandibular molar (wisdom tooth surgery). Patients filled out a form in the waiting room before their surgery. The form contained questions about their sex, age, and weight, and psychological questionnaires assessing anxiety, pain catastrophizing, and mindfulness (see descriptions below). You also got blood samples and saliva samples from participants in the waiting room 5 minutes before their operations to determine the serum (a component of the blood) and salivary cortisol levels of participants. Participants were contacted 5 hours after the surgery to see how much pain they were experiencing. The __level of pain__ at that moment was recorded using a numerical rating scale using a __scale of 0 to 10__, where 0 means “no pain” and 10 means “worst pain I can imagine”. 

__The State Trait Anxiety Inventory:__ T measures trait anxiety on a scale of 20 to 80, higher scores mean higher anxiety. Anxiety has been found in many studies to positively correlate with the level of pain experienced. This is __variable STAI_trait__ in the dataset. 

__The Pain Catastrophizing Scale__ measures the extent of pain catastrophizing, which is characterized by a tendency to magnify the threat value of a pain stimulus and to feel helpless in the presence of pain, as well as by a relative inability to prevent or inhibit pain-related thoughts in anticipation of, during, or following a painful event. The total score on this scale ranges from 0 to 52, higher scores mean higher catastrophizing. Pain catastrophizing is one of the well-established predictors of clinical pain. This is __variable pain_cat__ in the dataset.

__The Mindful Attention Awareness Scale (MAAS)__ measures dispositional mindfulness, which may be described as a tendency to turn attention to present-moment experiences in an open, non-judgemental way. The MAAS total score ranges from 1 to 6 (an average of the item scores), with higher scores representing higher dispositional mindfulness. Trait mindfulness has been theorized to serve as a protective factor against pain, as the individual would be more objective about their pain experience and tend to associate less discomfort, despair, and hopelessness to the pain-related sensations. This is __variable mindfulness__ in the dataset.

__Cortisol__ is a stress hormone associated with acute and chronic stress. Cortisol levels are thought to be positively associated with pain experience. Cortisol can be __measured from both blood and the saliva__, although, serum cortisol is often regarded in medical research as more reliably related to stress (serum is a component of the blood plasma). These are __variables cortisol_serum__, and __cortisol_saliva__ in the dataset.”

# Datasets

You will need two datasets for this assignment, datafile A and B. You can load them from the 'data/' folder.

# Task

First, fit a linear mixed model to estimate postoperative pain on datafile A. You should use the same fixed effect predictors as you used in your final model in the 3 assignment. (If you did not do that assignment, use the following predictors: age, sex, STAI, pain catastrophizing, mindfulness, and serum cortisol.) Importantly, the model has to account for the clustering of the data in different hospital sites. We have no reason to assume that the effects of the different predictors would be different in the different hospitals, so fit a random intercept model including the random intercept of hospital-ID. Once the model is built, note the model coefficients and the confidence intervals of the coefficients for all fixed effect predictors, and compare them to the ones obtained in the 3 assignment. 

Also, compute the variance explained by the fixed effect predictors using marginal R^2^, and the variance explained by the fixed and random effect terms combined using conditional R^2^. Now use the model coefficients obtained on data file A to predict pain in datafile B.

__IMPORTANT:__ Do not fit the regression models on data file B (don’t re-train your models), just use the regression equation you derived based on datafile A. These regression equations should be applied on the new data (datafile B), to predict pain.

Now compute the variance explained by the model on datafile B. You can do this by using the formula: __1 - (RSS / TSS) = R^2__. Compare this R^2^ to the marginal and conditional R^2^ values computed for the model on datafile A. 

# What to report

Report the model coefficients and the confidence intervals of the coefficients for each fixed effect predictor obtained on data file A in a table. 

Report the variance components for the fixed effects, the random intercept, and the residuals (from the model on data file A). Also report the marginal R^2^ and the conditional R^2^ squared obtained from the model on data file A, and the observed R^2^ of this model for data file B.

# What to discuss

Compare the model coefficients and the confidence intervals observed in this assignment and the assignment for Lab 2 and discuss what you think the differences or similarities mean.

# Solution

## Read the data

Read the datasets used in this assignment. Pay attention to the extensions of the datafiles.

```{r}
library(haven)

#dataset_A = read_sav(file.choose())
#View(dataset_A)
#dataset_B = read_sav(file.choose())
#View(dataset_B)

#uncomment to read in files

```

## Exploratory data analysis

Run an exploratory data analysis (EDA) to investigate the dataset.

```{r}
dataset_A %>%
  summary()


#using ggplot to find outliers and check normality
ggplot(dataset_A, aes(age, pain)) +
  geom_point()
ggdensity(dataset_A$age, xlab = "normality of age")
ggdensity(dataset_A$pain, xlab = "normality of pain")
```

```{r}
ggplot(dataset_A, aes(age, IQ)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
ggdensity(dataset_A$IQ, xlab = "normality of IQ")
```

```{r}
ggplot(dataset_A, aes(age, weight)) +
  geom_point()
ggdensity(dataset_A$weight, xlab = "normality of weight")
```

```{r}
ggplot(dataset_A, aes(age, household_income)) +
  geom_point()
ggdensity(dataset_A$household_income, xlab = "normality of household income")
```

```{r}
is.factor(dataset_A$sex)
dataset_A <- 
  dataset_A %>%
  mutate(sex = as.factor(sex))
levels(dataset_A$sex)
```

```{r}
ggplot(dataset_B, aes(age, pain)) +
  geom_point()
ggdensity(dataset_B$pain, xlab = "normality of pain")
ggdensity(dataset_B$age, xlab = "normality of age")
```

```{r}
ggplot(dataset_B, aes(age, IQ)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
ggdensity(dataset_B$IQ, xlab = "normality of IQ")
```

```{r}
ggplot(dataset_B, aes(age, weight)) +
  geom_point()
ggdensity(dataset_B$weight, xlab = "normality of weight")
```

```{r}
ggplot(dataset_B, aes(age, household_income)) +
  geom_point()
ggdensity(dataset_B$household_income, xlab = "normality of household income")
```

```{r}
dataset_B <- dataset_B %>%
  mutate(sex = as.factor(sex))
```

## Correct coding errors

If you find values in the dataset during the EDA, that are not correct based on the provided descriptions of the variables of the dataset please correct them here.

```{r}
dataset_A <- dataset_A %>%
   mutate(sex = replace(sex, sex == "Male", "male")) %>%
  filter(weight > 40)

#no signif problem with B data
```

##model

```{r}
model_A <- lm(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum, data = dataset_A)
check_model(model_A)
summary(model_A)
```

```{r}

model_A %>%
  augment() %>%
  arrange(desc(.cooksd)) %>%
  head()


r.squaredGLMM(model_A)

#model_A is a significant model (F(6,192)=17.74, p = 0.004), with significant variables age (p < 0.001), sex (p = 0.039), mindfulness (p = 0.012) and cortisol serum (p < 0.001)
```

```{r}
mixed_model_A <- lmer(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum + (1 | hospital), data = dataset_A)
check_model(mixed_model_A)

#random effect of hospitals
```


```{r}
summary(model_A)
confint(model_A)
summary(mixed_model_A)
confint(mixed_model_A)


r.squaredGLMM(mixed_model_A)

#the marginal R^2 is 0.316, meaning the variance explained by the fixed factors of the model is 31.6%.

#the conditional R^2 is 0.435, meaning the variance explained by the model containing fixed and random effects is higher, 43.5%.

#to run my model on the data in dataset B, I made sure that the variables are named the same.

#I predicted values in B using the mixed model I have gotten from dataset A
```

```{r}
comparison <- anova(mixed_model_A, model_A)
comparison

#the complex mixed model is a significantly better choice (p < 0.001)**
```

```{r}
predict_on_B <- predict(mixed_model_A, dataset_B, allow.new.levels = TRUE)
predict_on_B

predict(mixed_model_A,dataset_B, allow.new.levels = TRUE) - dataset_B$pain
sum(predict_on_B^2)
```

```{r}
glance(model_A, dataset_B)

#the fitted fixed effect model on database A predicts 33.7% of the pain's variance in dataset B (adj R^2 = 0.337).

#Compared to the modelA fitted on dataset A it seems to be lower than both the marginal (0.35), and the conditional (0.35).

#it suggest that model_A predicts better on dataset A than on dataset B
```

